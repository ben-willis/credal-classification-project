\chapter{Applying of the naive Bayes classifier}

\section{Maximum Likelihood Estimate}
We will use the naivety assumption to find the maximum likelihood estimate for an object's class. The naivety assumptions is that all the features of an object are independent \cite{Zaffalon01}. We can write this as:
\begin{equation} \label{naivety}
	P(\mathbf{a} \mid c) = \prod_{i=1}^{k} P(a_i \mid c)
\end{equation}

The maximum likelihood estimate (MLE) is the class which maximizes the probability in \cref{naivety}. i.e. $\hat{c} = \argmax_{c \in \mathcal{C}} P(\mathbf{a} \mid c)$.

\section{Classification}
To begin with we take three pieces of vehicular information and train these against the experts assessed risk with our classifier. The three features we use are price, body style and horsepower of the vehicle. These were selected as they do not show strong levels of correlation and are therefore a good fit for the naivety assumption. In the case of price and horsepower we split the data into 10 equally sized intervals to discretize the data. We also remove any rows with missing values to simplify the process.

We estimate the probabilities required to find the maximum likelihood estimate by using the relative frequencies of each of the features given each of the possible classes in our training set.

\section{The Data}
The data set we will be analysing contains vehicular information about 205 auto mobiles. This features includes dimensions, engine specifications and vehicle characteristics. It also contains an experts assessed risk to the insurer of the vehicle on an integer scale of -2 to 3 with 3 being most risky and -2 being least risky. In addition to the technical information and the experts assessment the data set also contains the normalized loss to the insurer. This ranges from 65 to 256 and is normalized for all vehicles within a particular size classification (two-door small, station wagons, etc) and represents the average loss per car per year \cite{Automobile}.

Initially we will only examine a selection of the vehicular information. Also we will start by aiming to replicate the expert's assessment of risk using our chosen classifier.

\section{Diagnostics}

The metric we will use to measure the success of our classifier is \textit{accuracy}. Accuracy is the probability of successfully assigning a class to an object. Estimating this is important as it is a useful measure for deciding which model to apply to a given problem \cite{Kohavi95}.

Cross validation, or $k$-fold cross validation is a method for estimating accuracy. In $k$-fold cross validation the dataset is split into k roughly equally sized groups. For each of these groups the rest of the data is used to train the classifier and then the  data from the remaining group is used to test the classifier. After this process has been completed for all the groups the average success rate of the classifier is considered \cite{Priddy05}.

The choice of $k$ is leads to different types of cross validation. A standard choice is $k=10$ \cite{Priddy05}. A special case of cross validation is when $k=n$ (the number of observations). This is knowns as \textit{Leave-one-out cross validation}.