\newcommand{\sn}[2]{\ensuremath{{#1}\times 10^{#2}}}

\chapter{Imprecise Prior}

When estimating the probabilities for our classifier we take in to account our prior beliefs for them and the likelihood given a set of observations.

When we initially chose our prior distribution we chose the parameters in \cref{initial prior} to represent our indifference towards the classes and attributes.
However this prior is still informative and does not truly represent our lack of prior knowledge about the parameters.
We need a way to represent this lack of knowledge.

\section{Imprecise Dirichlet Model}

The imprecise Dirichlet model is a model for this lack of knowledge.
Instead of using a single prior distribution to represent our beliefs about the unknown parameters we use a set of prior distributions.
In the imprecise Dirichlet models the prior distributions are Dirichlet distribution however we will use a set of the distributions in \cref{prior} for a fixed value of $s$.
The parameter $s$ represents the strength of our prior beliefs and determines how quickly our classifier learns.

Using this model we can find the upper and lower bounds for each posterior expectation based on different prior distributions.
We can then take these to be upper and lower estimates for the probabilities.
For our distributions the upper and lower bounds are given by:
\begin{align}
	\overline{E}(\theta_c \mid s, \mathbf{n}) & = \frac{n(c) + s}{N+s} = \overline{P}(c) \\
	\underline{E}(\theta_c \mid s, \mathbf{n}) & = \frac{n(c)}{N+s} = \underline{P}(c)
\end{align}
These occur when we use the prior distributions with $t(c) = 0$ and $t(c) = 1$ respectively.

Similarly we have:
\begin{align}
	\overline{E}(\theta_{a_i \mid c} \mid s, \mathbf{n}) & = \frac{n(a_i, c) + s}{n(c)+s} = \overline{P}(a_i \mid c) \\
	\underline{E}(\theta_{a_i \mid c} \mid s, \mathbf{n}) & = \frac{n(a_i, c)}{n(c)+s} = \underline{P}(a_i \mid c)
\end{align}
These occur when we use the prior distributions with $t(c) = 1$, $t(a_i, c)=1$ and $t(c) = 1$, $t(a_i, c)=0$ respectively.

Now that we have intervals for these probabilities we need a decision mechanism to assign a risk rating to a vehicle.
Let's start by comparing how our classifier behaves if we assume the true probability is at each end of the interval.
We will use the 0-1 loss function for the actual classification and estimate each probability $P(\cdot)$ to be either the upper or lower probability of our interval.
We will measure accuracy and random classifications as before.

\begin{center}
	\begin{tabular}{l|c c}
	                & Accuracy & Random Assignments \\
	\hline
	Lower Estimates & 62.17\%  & 20.02\%            \\
	Upper Estimates & 10.88\%  & 0\%                \\
	\end{tabular}
\end{center}

Neither of these offer a sufficient classification.
The lower estimates randomly assign classes too often and the upper estimates have a terrible accuracy.

\section{Simple Credal Classifier}
Alternatively we can turn our classifier into a credal classifier.
A credal classifier assigns a set of classes as opposed to a single class to an object.
We will call the set of classes that are returned the credal set.

Recall the MAP estimate for the risk rating of a vehicle given by \cref{map}.
We say that a class $c'$ is dominated by $c''$ if:
\begin{equation}\label{Credal Dominance}
P(c' \mid \mathbf{a}) < P(c'' \mid \mathbf{a})
\end{equation}
for all values of $\mathbf{t}$ in our prior model.
This is because the MAP estimate for the class will always choose $c''$ over $c'$ regardless of which prior is used.
Note that this is equivalent to $P(c', \mathbf{a}) < P(c'', \mathbf{a})$ as $P(\mathbf{a})$ is just a normalizing constant.

We can use the bounds for the probabilities we found earlier to create an interval $P(c, \mathbf{a})$ must lie in. 

If we look at the intervals created by the upper and lower estimates we achieve:
\begin{equation}
	P(c, \mathbf{a}) \in \left[ \underline{P}(c)\prod_{i=1}^k \underline{P}(a_i \mid c), \overline{P}(c)\prod_{i=1}^k \overline{P}(a_i \mid c) \right]
\end{equation}
for each $c \in \mathcal{C}$.
This is true because:
\begin{equation}
\underline{P}(c)\prod_{i=1}^k \underline{P}(a_i \mid c) < \underline{P}(c, \mathbf{a}) < P(c, \mathbf{a}) < \overline{P}(c, \mathbf{a}) < \overline{P}(c)\prod_{i=1}^k \overline{P}(a_i \mid c)
\end{equation}
for all choices of $\mathbf{t}$
We can use the above intervals to create a simple credal classifier.

For an example consider the following intervals:
\begin{center}
	\begin{tabular}{l|c c}
	Risk Rating & Lower Bound & Upper Bound \\
	\hline
	-2          & $0$              & $\sn{3.12}{-9}$  \\
	-1          & $0$              & $\sn{8.91}{-16}$ \\
	0           & $\sn{3.81}{-15}$ & $\sn{2.30}{-13}$ \\
	1           & $\sn{2.19}{-9}$  & $\sn{2.34}{-8}$  \\
	2           & $\sn{1.88}{-13}$ & $\sn{6.22}{-11}$ \\
	3           & $0$              & $\sn{5.82}{-17}$ \\
	\end{tabular}
\end{center}
We can see the classes -1, 0, 2 and 3 are dominated by 1.
However the risk rating of -2 is not dominated by 1 as $\sn{3.12}{-9} > \sn{2.19}{-9}$.
Hence our credal classifier returns the set or risk ratings $\{-2, 1\}$.
Note that in this particular example the true risk rating was 1 so our credal classifer was correct to include it in the set of possible classes.

We now need a way to test this classifier.
We cannot use our previous measure of accuracy as this classifier may not return a single class.
Instead there are a few metrics we can use for our diagnostics:
\begin{description}
	\item[A\%] Accuracy of the credal classifier when a single class is returned
	\item[B\%] Percentage of objects for which the true class is in the credal set
	\item[C\%] Percentage of objects for which the credal set contains more than one class
\end{description}

We will vary the choice of the hyper parameter s when measuring these three statistics.
\begin{center}
\begin{tabular}{l|c c c}
        & A\%     & B\%     & C\%     \\
\hline
s = 0.5 & 77.50\% & 88.08\% & 57.51\% \\
s = 1   & 77.70\% & 90.67\% & 81.35\% \\
s = 2   & 75.00\% & 94.30\% & 96.89\% \\
s = 5   & -       & 97.92\% & 100\%   \\
\end{tabular}
\end{center}

We see that the accuracy of our classifier when a single class is returned remains almost constant for the different s parameters.
We also note that this accuracy is greater than the accuracy of our corrected naive Bayes classifier on the same data set.
However we notice that varying the s parameter has an effect on the other two metrics.
Increasing the value of $s$ increases the percentage of objects for which the credal set contains more than one class.
It also increases the percentage of objects for which the true class is in the credal set.

This effect can be easily explained.
Increasing the s value increases the upper bound and decreases the lower bound on each of the probabilities being estimated.
Hence increasing the value of s increases the size of the interval and increasing the size of the interval leads to less intervals being dominated and less classes being excluded.

\section{Alternate Credal Classifier}
In the simple credal classifier we estimated the lower and upper bounds for each probability separately using our imprecise prior model.
We then used these separate estimates to make inferences about the true probability of interest $P(c \mid \mathbf{a})$.

% However an alternate method for credal classification.
We can rewrite our original definition of credal dominance \cref{Credal Dominance} as:
\begin{equation}
	\frac{P(c' \mid \mathbf{a})}{P(c'' \mid \mathbf{a})} = \frac{P(c')\prod_{i=1}^{k}P(a_i \mid c')}{P(c'')\prod_{i=1}^{k}P(a_i \mid c'')} > 1
\end{equation}
Note that the equality holds because the constant $P(\mathbf{a})$ is cancelled.

If we plug in the posterior expectation for our parametrisation as an estimate for the probabilities then we arrive at:
\begin{equation}
	\frac{n(c')+st(c')}{n(c'')+st(c'')} \prod_{i=1}^k \frac{n(a_i, c') + st(a_i , c')}{n(c'') + st(c'')} \frac{n(c'') + st(c'')}{n(a_i, c') + st(a_i , c')} > 1
\end{equation}

When we use our imprecise prior determining whether this inequality holds we can solve the optimization problem:
\begin{align}
	\min & \left[ \frac{n(c'')+st(c'')}{n(c')+st(c')} \right]^{k-1} \prod_{i=1}^k \frac{n(a_i, c') + st(a_i , c')}{n(a_i, c'') + st(a_i , c'')} \\
	s.t. & \sum_{c \in \mathcal{C}} t(c) = 1 \\
	& 0 < t(a_i, c) < t(c)
\end{align}
Then compare the answer to 1.
This is the same optimization problem as described by Zaffalon \cite{Zaffalon01}.

It is possible to manipulate this problem into an easier to solve form.
Firstly note that the minimum is achieved when each $t(a_i, c') \rightarrow 0$ and $t(a_i, c'') \rightarrow t(c'')$ so we can use these values in the objective function.
Furthermore, at the minimum, we have $t(c') = 1 - t(c'')$.
To simplify the problem set $t(c'') = x$ then our optimization problem becomes a problem in a single variable:
\begin{align}
	\min \quad & \left[ \frac{n(c'') + sx}{n(c')+s - sx} \right]^{k-1} \prod_{i=1}^k \frac{n(a_i, c')}{n(a_i, c'') + sx} \\
	\text{s.t.} \quad & 0 < x < 1
\end{align}
As a reminder we say the class $c'$ dominates the class $c''$ if this minimum is greater than 1.